{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNISTGAN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMEVyG3QYPpTNxuI8XKI0c5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nathanbarry474/google-colab-notebooks/blob/master/MNISTGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdkUkjAQ7jXX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing the libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchvision import datasets, transforms, models\n",
        "import torchvision\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpebvbE3lr0G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create directory to store results\n",
        "os.makedirs('output', exist_ok=True)\n",
        "\n",
        "img_shape = (1, 28, 28)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6Fw1Nq0o3pr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating the Generator\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Generator, self).__init__()\n",
        "    self.fc1 = nn.Linear(100, 128)\n",
        "    self.in1 = nn.BatchNorm1d(128)\n",
        "    self.fc2 = nn.Linear(128, 512)\n",
        "    self.in2 = nn.BatchNorm1d(512)\n",
        "    self.fc3 = nn.Linear(512, 1024)\n",
        "    self.in3 = nn.BatchNorm1d(1024)\n",
        "    self.fc4 = nn.Linear(1024, 28*28)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.leaky_relu(self.in1(self.fc1(x)), 0.2)\n",
        "    x = F.leaky_relu(self.in2(self.fc2(x)), 0.2)\n",
        "    x = F.leaky_relu(self.in3(self.fc3(x)), 0.2)\n",
        "    x = F.tanh(self.fc4(x))\n",
        "    return x.view(x.shape[0], *img_shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1626LVnq_P3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating the Discriminator\n",
        "class Discriminator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Discriminator, self).__init__()\n",
        "    self.fc1 = nn.Linear(28*28, 512)\n",
        "    self.fc2 = nn.Linear(512, 256)\n",
        "    self.fc3 = nn.Linear(256, 128)\n",
        "    self.fc4 = nn.Linear(128, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.view(x.size(0), -1)\n",
        "    x = F.leaky_relu(self.fc1(x), 0.2)\n",
        "    x = F.leaky_relu(self.fc2(x), 0.2)\n",
        "    x = F.leaky_relu(self.fc3(x), 0.2)\n",
        "    x = F.sigmoid(self.fc4(x))\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehOOFPRIt3ho",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initializing the classes\n",
        "generator = Generator()\n",
        "discriminator = Discriminator()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeGXhP9ruG09",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading the dataset\n",
        "bs = 64\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "trainset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
        "\n",
        "trainloader = DataLoader(trainset, batch_size=bs, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MM7AdZXwUXo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f2997d34-0c42-4154-9e7c-83b382a2f405"
      },
      "source": [
        "# Check for GPU\n",
        "if torch.cuda.is_available():\n",
        "  generator.cuda()\n",
        "  discriminator.cuda()\n",
        "  loss_func.cuda()\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8uYAgwfwpZB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating the optimizers\n",
        "G_optimizer = torch.optim.Adam(generator.parameters(), lr=0.0002, betas=(0.4, 0.999))\n",
        "D_optimizer = torch.optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.4, 0.999))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uijttRujyYYk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Tensor = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZR1KlIOH2u8q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a31000a1-fedf-4965-f784-90624edf9d05"
      },
      "source": [
        "# Training for loop\n",
        "epochs = 2\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  for i, (X, _) in enumerate(trainloader):\n",
        "\n",
        "    # Defining real and fake\n",
        "    # real = Tensor(X.size(0), 1).fill_(1.0)\n",
        "    # fake = Tensor(X.size(0), 1).fill_(0.0)\n",
        "    mb_size = X.size(0)\n",
        "    real = torch.ones(mb_size, 1)\n",
        "    fake = torch.zeros(mb_size, 1)\n",
        "\n",
        "    if torch.cuda.is_available() == True:\n",
        "      real_imgs = X.cuda()\n",
        "    else:\n",
        "      real_imgs = X\n",
        "\n",
        "    G_optimizer.zero_grad()\n",
        "\n",
        "    G_input = Tensor(np.random.normal(0, 1, (X.shape[0], 100)))\n",
        "\n",
        "    # Creating the fake image\n",
        "    G = generator(G_input)\n",
        "\n",
        "    # Create Generator loss function\n",
        "    G_loss = F.binary_cross_entropy(discriminator(G), real)\n",
        "    G_loss.backward()\n",
        "    G_optimizer.step()\n",
        "\n",
        "    D_optimizer.zero_grad()\n",
        "\n",
        "    real_loss = F.binary_cross_entropy(discriminator(real_imgs), real)\n",
        "    fake_loss = F.binary_cross_entropy(discriminator(G.detach()), fake)\n",
        "    D_loss = (real_loss + fake_loss)\n",
        "\n",
        "    D_loss.backward()\n",
        "    D_optimizer.step()\n",
        "\n",
        "    print (\"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\" % \n",
        "           (epoch, 20, i, len(trainloader), D_loss.item(), G_loss.item()))\n",
        "\n",
        "    total_batch = epoch * len(trainloader) + i\n",
        "    if total_batch % 400 == 0:\n",
        "      torchvision.utils.save_image(G.data[:25], './output/%d.png' % total_batch, nrow=5, normalize=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[Epoch 0/20] [Batch 0/938] [D loss: 1.386544] [G loss: 0.744311]\n",
            "[Epoch 0/20] [Batch 1/938] [D loss: 1.385953] [G loss: 0.744550]\n",
            "[Epoch 0/20] [Batch 2/938] [D loss: 1.384624] [G loss: 0.744314]\n",
            "[Epoch 0/20] [Batch 3/938] [D loss: 1.384537] [G loss: 0.744394]\n",
            "[Epoch 0/20] [Batch 4/938] [D loss: 1.389061] [G loss: 0.743707]\n",
            "[Epoch 0/20] [Batch 5/938] [D loss: 1.387528] [G loss: 0.744369]\n",
            "[Epoch 0/20] [Batch 6/938] [D loss: 1.387593] [G loss: 0.743520]\n",
            "[Epoch 0/20] [Batch 7/938] [D loss: 1.386473] [G loss: 0.744382]\n",
            "[Epoch 0/20] [Batch 8/938] [D loss: 1.387883] [G loss: 0.743532]\n",
            "[Epoch 0/20] [Batch 9/938] [D loss: 1.387345] [G loss: 0.744149]\n",
            "[Epoch 0/20] [Batch 10/938] [D loss: 1.385799] [G loss: 0.743610]\n",
            "[Epoch 0/20] [Batch 11/938] [D loss: 1.386323] [G loss: 0.744214]\n",
            "[Epoch 0/20] [Batch 12/938] [D loss: 1.386132] [G loss: 0.744174]\n",
            "[Epoch 0/20] [Batch 13/938] [D loss: 1.384783] [G loss: 0.744058]\n",
            "[Epoch 0/20] [Batch 14/938] [D loss: 1.385975] [G loss: 0.744264]\n",
            "[Epoch 0/20] [Batch 15/938] [D loss: 1.387063] [G loss: 0.743573]\n",
            "[Epoch 0/20] [Batch 16/938] [D loss: 1.388481] [G loss: 0.743416]\n",
            "[Epoch 0/20] [Batch 17/938] [D loss: 1.385409] [G loss: 0.743493]\n",
            "[Epoch 0/20] [Batch 18/938] [D loss: 1.385210] [G loss: 0.744263]\n",
            "[Epoch 0/20] [Batch 19/938] [D loss: 1.387395] [G loss: 0.744604]\n",
            "[Epoch 0/20] [Batch 20/938] [D loss: 1.387680] [G loss: 0.743534]\n",
            "[Epoch 0/20] [Batch 21/938] [D loss: 1.387914] [G loss: 0.743438]\n",
            "[Epoch 0/20] [Batch 22/938] [D loss: 1.385756] [G loss: 0.744523]\n",
            "[Epoch 0/20] [Batch 23/938] [D loss: 1.387228] [G loss: 0.744104]\n",
            "[Epoch 0/20] [Batch 24/938] [D loss: 1.384888] [G loss: 0.744042]\n",
            "[Epoch 0/20] [Batch 25/938] [D loss: 1.387838] [G loss: 0.743212]\n",
            "[Epoch 0/20] [Batch 26/938] [D loss: 1.387277] [G loss: 0.744009]\n",
            "[Epoch 0/20] [Batch 27/938] [D loss: 1.387444] [G loss: 0.743508]\n",
            "[Epoch 0/20] [Batch 28/938] [D loss: 1.386714] [G loss: 0.744422]\n",
            "[Epoch 0/20] [Batch 29/938] [D loss: 1.387858] [G loss: 0.743856]\n",
            "[Epoch 0/20] [Batch 30/938] [D loss: 1.385620] [G loss: 0.744581]\n",
            "[Epoch 0/20] [Batch 31/938] [D loss: 1.384541] [G loss: 0.743905]\n",
            "[Epoch 0/20] [Batch 32/938] [D loss: 1.387878] [G loss: 0.743954]\n",
            "[Epoch 0/20] [Batch 33/938] [D loss: 1.388491] [G loss: 0.744276]\n",
            "[Epoch 0/20] [Batch 34/938] [D loss: 1.386304] [G loss: 0.744365]\n",
            "[Epoch 0/20] [Batch 35/938] [D loss: 1.383878] [G loss: 0.744254]\n",
            "[Epoch 0/20] [Batch 36/938] [D loss: 1.386111] [G loss: 0.744253]\n",
            "[Epoch 0/20] [Batch 37/938] [D loss: 1.387891] [G loss: 0.744230]\n",
            "[Epoch 0/20] [Batch 38/938] [D loss: 1.385153] [G loss: 0.744562]\n",
            "[Epoch 0/20] [Batch 39/938] [D loss: 1.385814] [G loss: 0.744237]\n",
            "[Epoch 0/20] [Batch 40/938] [D loss: 1.388290] [G loss: 0.744181]\n",
            "[Epoch 0/20] [Batch 41/938] [D loss: 1.386803] [G loss: 0.744261]\n",
            "[Epoch 0/20] [Batch 42/938] [D loss: 1.385962] [G loss: 0.743871]\n",
            "[Epoch 0/20] [Batch 43/938] [D loss: 1.388693] [G loss: 0.743670]\n",
            "[Epoch 0/20] [Batch 44/938] [D loss: 1.387137] [G loss: 0.743875]\n",
            "[Epoch 0/20] [Batch 45/938] [D loss: 1.387120] [G loss: 0.744314]\n",
            "[Epoch 0/20] [Batch 46/938] [D loss: 1.387628] [G loss: 0.743627]\n",
            "[Epoch 0/20] [Batch 47/938] [D loss: 1.384733] [G loss: 0.744605]\n",
            "[Epoch 0/20] [Batch 48/938] [D loss: 1.386432] [G loss: 0.744344]\n",
            "[Epoch 0/20] [Batch 49/938] [D loss: 1.386591] [G loss: 0.744421]\n",
            "[Epoch 0/20] [Batch 50/938] [D loss: 1.389706] [G loss: 0.743959]\n",
            "[Epoch 0/20] [Batch 51/938] [D loss: 1.385826] [G loss: 0.744555]\n",
            "[Epoch 0/20] [Batch 52/938] [D loss: 1.387044] [G loss: 0.744175]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-017c41dfc147>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# Create Generator loss function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mG_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mG_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mG_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}